# 颜色量化算法逻辑梳理

本文档旨在详细梳理项目中涉及的三种主要颜色量化算法的内部逻辑：

1.  `RgbQuant.js` (基于颜色流行度的聚类算法)
2.  `pnnquant.js` (原始的“最近邻”神经网络算法)
3.  `pnnquant2.esm.js` + `GpuQuantizer.js` (我们改进的 CPU + GPU 混合算法)

---

## 1. RgbQuant.js 逻辑分析

`RgbQuant.js` 是一个基于**“颜色流行度” (Color Popularity)** 和 **“迭代聚类” (Iterative Clustering)** 的颜色量化算法。它的核心思想是：先找出图像中出现频率最高的颜色，然后通过不断合并相似颜色的方式，将这些颜色精简到目标数量，最终形成调色板。

整个过程可以分为三个主要阶段：

1.  **采样 (Sampling)**：统计图像中的颜色分布，建立直方图。
2.  **调色板构建 (Palette Building)**：从成千上万的颜色中，通过合并相似色，生成一个小的、具有代表性的调色板。
3.  **颜色映射 (Color Mapping)**：将原图的每个像素替换为调色板中与它最接近的颜色，生成最终的量化图像。

下面是这三个阶段的详细分解：

### 1.1. 采样阶段 (`sample` 方法)

此阶段的目标是回答“图像中都有哪些颜色？它们各出现了多少次？”。`RgbQuant` 提供了两种采样策略，通过 `method` 选项控制：

*   **`method: 1` - 全局统计 (`colorStats1D`)**
    *   **逻辑**: 这是最简单直接的方法。它会遍历图像中的**每一个像素**，然后在一个全局的直方图对象 (`this.histogram`) 中为该像素的颜色值进行计数。
    *   **优点**: 简单，能确保统计到所有颜色。
    *   **缺点**: 对于色彩丰富的大图，直方图会变得非常庞大，占用大量内存。同时，它无法区分重要的主体颜色和无意义的噪点颜色。

*   **`method: 2` - 局部阈值统计 (`colorStats2D`) (默认)**
    *   **逻辑**: 这是一种更智能、更高效的方法。它首先将图像分割成一个个小方块（例如 64x64 像素，由 `boxSize` 控制）。
    *   然后，它在**每个小方块内部**进行颜色统计。只有当某个颜色在一个小方块内出现的次数达到了一个阈值 (`boxPxls`)，这个颜色才会被认为“足够重要”，并被添加到全局直方图 (`this.histogram`) 中。
    *   **优点**: 极大地过滤了图像中的噪点和孤立的杂色像素。只有在局部区域内形成一定规模的颜色才会被考虑，这使得最终的调色板更能反映图像的主要色块。
    *   **缺点**: 可能会丢失那些虽然全局数量少、但视觉上很重要的颜色（例如一幅画中的点睛之笔）。

> **注意**: 在这两个采样过程中，完全透明的像素 (`alpha = 0`) 都会被直接忽略。

### 1.2. 调色板构建阶段 (`buildPal` 和 `reducePal` 方法)

这是算法最核心、最复杂的部分。在采样完成后，我们得到了一个包含很多颜色及其频率的直方图。此阶段的目标就是从这个直方图中“提炼”出最终的调色板。

1.  **初始颜色筛选**:
    *   首先，将直方图中的所有颜色按照**出现频率**从高到低排序。
    *   根据采样方法的不同，选取一个初始的颜色集合：
        *   如果使用 `method: 1`，会选取前 `initColors` 个（默认 4096）最高频的颜色。
        *   如果使用 `method: 2`，会选取所有进入了全局直方图的颜色。

2.  **迭代合并相似色 (`reducePal`)**:
    *   这是关键的**聚类**步骤。算法会不断地合并颜色，直到数量减少到目标值 (`opts.colors`)。
    *   它在一个 `while` 循环中执行，循环条件是 `当前调色板颜色数量 > 目标数量`。
    *   在每次循环中：
        a.  它会遍历调色板中的**每一对颜色**。
        b.  计算这对颜色之间的**感知距离**（可以使用欧几里得距离 `distEuclidean` 或曼哈顿距离 `distManhattan`）。
        c.  如果距离小于一个动态的**合并阈值 (`thold`)**，就认为这两个颜色“足够相似”，并将其中一个从调色板中移除（合并）。
        d.  完成一轮遍历后，**增大合并阈值 `thold`**。这意味着，算法会先合并最最相似的颜色（比如几乎一样的深蓝色和黑色），然后随着阈值放宽，再慢慢地合并差异稍大一些的颜色（比如深红色和橙色）。
    *   这个过程不断重复，像漏斗一样筛选颜色，直到调色板的尺寸达标。

3.  **过少修正**:
    *   在最后一次合并中，有可能因为阈值过大而“用力过猛”，导致调色板颜色数量少于目标值（例如目标是 16 色，结果只剩下 14 色）。
    *   `RgbQuant` 有一个巧妙的补偿机制：它会记录下最后一次合并中所有被移除的颜色，并按照它们被合并时的“距离”从大到小排序。然后，它会从这个列表里把“最不相似”（即合并时距离最大）的颜色重新加回调色板，直到数量刚好达到目标值。

### 1.3. 颜色映射阶段 (`reduce` 和 `dither` 方法)

当调色板生成后，最后一步就是用这个调色板来“重绘”原始图像。

*   **无抖动映射 (`reduce`)**:
    *   这是最简单的映射方式。它遍历原始图像的每一个像素。
    *   对于每个像素，调用 `nearestIndex` 方法。这个方法会遍历**整个最终调色板**，计算原始像素颜色与调色板中每种颜色的距离，并找出距离最小的那个颜色。
    *   然后将原始像素的颜色替换为找到的这个最接近的调色板颜色。

*   **带抖动映射 (`dither`)**:
    *   抖动（Dithering）是一种视觉欺骗技术，用于在有限的颜色下模拟出更丰富的色彩层次，避免出现大面积的色块（Color Banding）。
    *   当一个像素被替换为调色板颜色后，会产生一个“量化误差”（即原始色与新颜色的差值）。
    *   抖动算法（如 `FloydSteinberg`）不会丢弃这个误差，而是按照特定的比例，将这个误差**扩散**到该像素周围尚未处理的邻近像素上。
    *   这样一来，下一个像素在计算最近色之前，它的颜色值已经被上一个像素的误差所轻微改变。这使得整体画面产生一种精细的噪点纹理，从而在宏观上模拟出平滑的颜色过渡。

### 1.4. 总结与图示

`RgbQuant` 是一个经典但计算密集型的算法。它的优势在于 `method: 2` 的局部采样和抖动功能，可以产生不错的视觉效果。其主要瓶颈在于性能：无论是调色板构建时的 `O(N^2)` 聚类，还是颜色映射时对每个像素都要遍历整个调色板，都导致它在处理大图时速度较慢。

```mermaid
graph TD
    subgraph "1. 预量化与直方图 (Binning)"
        A[原始图像] --> B[遍历所有像素];
        B --> C{"getARGBIndex(pixel)"};
        C --> D[将 24/32bit 颜色映射到 16bit 索引];
        D --> E[在 bins[] 数组中累加颜色和数量];
        E --> F[计算每个 bin 的平均色];
    end

    subgraph "2. 层次聚类 (Clustering)"
        F --> G[为每个 bin 计算最近邻(nn)和合并误差(err)];
        G --> H[将所有 bin 根据 err 构建一个最小堆];
        H --> I{循环 N 次 (直到数量达标)};
        I -- "是" --> J[从堆顶取出误差最小的 bin];
        J --> K[合并该 bin 和它的最近邻];
        K --> L[更新受影响的 bin 的 nn 和 err];
        L --> M[调整堆];
        M --> I;
        I -- "否" --> N[最终调色板];
    end

    subgraph "3. 颜色映射 (Mapping)"
        O[原始图像] --> P{选择映射方式};
        N --> P;
        P -- "有序抖动" --> Q1[为像素找最接近的2个颜色, 用蓝噪声选择其一];
        P -- "错误扩散抖动" --> Q2[找最近色, 并将误差扩散到邻近像素];
        Q1 --> R[最终量化图像];
        Q2 --> R;
    end
```

## 2. PnnQuant.js 逻辑分析

`PnnQuant` (Pairwise Nearest Neighbor Quantizer) 是一种与 `RgbQuant` 思路截然不同的颜色量化算法。它不依赖于颜色流行度，而是将量化问题视为一个**聚类问题**，并采用一种高效的、基于 **“成对最近邻”** 思想的层次聚类算法来解决。

其核心思想是：将图像中相似的颜色看作初始的“簇”（或称为 `bin`），然后反复寻找并合并最相似的两个簇，直到簇的数量减少到我们期望的调色板大小。这种方法的性能和质量都非常出色。

整个过程可以分为三个主要阶段：

1.  **颜色空间降维与直方图构建 (Binning)**：通过位运算快速将 24/32 位颜色空间压缩到 15/16 位，极大地减少初始颜色数量，并统计每个“颜色桶 (`bin`)”的平均色值和像素数量。
2.  **基于最小误差的迭代合并 (Clustering via Heap)**：使用一个**最小堆 (Min-Heap)** 数据结构来高效地、反复地找出并合并那些“合并后对整体图像质量损失最小”的一对颜色。
3.  **颜色映射与抖动 (Mapping & Dithering)**：将原始像素映射到最终生成的调色板上，并提供了高质量的抖动算法来优化视觉效果。

下面是详细的逻辑分解：

### 2.1. 颜色空间降维与直方图构建 (`pnnquan` 方法 - 阶段一)

这是 `PnnQuant` 性能优势的第一个关键步骤。它没有直接处理图像中数百万种可能的颜色，而是先做了一次高效的“预量化”。

1.  **遍历像素**: 算法遍历输入图像的每一个像素。
2.  **颜色索引化 (`getARGBIndex`)**: 对每个像素的 RGBA 值，它并不直接使用，而是通过 `getARGBIndex` 函数将其转换成一个 15 或 16 位的索引值。这个函数通过**位掩码和位移**操作，丢弃了每个颜色通道（R, G, B）的几个最低有效位。
    *   例如，对于不透明图像，它将 `R(8位)G(8位)B(8位)` 映射为 `R(5位)G(6位)B(5位)` 的格式。
    *   **效果**: 这相当于将整个 1677 万色的空间，预先划分成了 65536 个“桶”（bin）。所有落入同一个桶的原始颜色，都会被认为是相似的，并被归为一类。这一步极大地降低了问题的复杂度。
3.  **构建直方图**:
    *   算法使用一个大数组 `bins` 作为直方图。上面计算出的 16 位索引就直接作为这个数组的下标。
    *   每个 `bin` 是一个 `PnnBin` 对象，它记录了这个桶内所有像素的**颜色总和**（`rc`, `gc`, `bc`, `ac`）和**像素总数**（`cnt`）。
4.  **计算平均色**: 遍历完所有像素后，再次遍历 `bins` 数组，将每个 `bin` 的颜色总和除以其像素总数，得到这个 `bin` 的**平均颜色**。

至此，我们获得了一个数量远少于原始颜色数（最多 65536 个）的初始颜色簇集合，每个簇都代表了图像中的一部分颜色，并有其平均色值和权重（像素数）。

### 2.2. 基于最小误差的迭代合并 (`pnnquan` 方法 - 阶段二)

这是算法的核心，也是其“Pairwise Nearest Neighbor”名称的由来。目标是将 `maxbins` 个颜色簇减少到 `nMaxColors` 个。

1.  **寻找最近邻 (`find_nn`)**: 对于每一个 `bin`，需要找到与它“最相似”的另一个 `bin`，即它的“最近邻”。
    *   **误差计算**: 两个 `bin` 合并后会产生多少“误差”？`find_nn` 函数通过一个加权的欧几里得距离公式来衡量。它不仅考虑了颜色在 RGB 空间中的距离，还考虑了每个 `bin` 的像素数量（`cnt`）。合并两个像素数很多的 `bin` 会比合并两个像素数很少的 `bin` 产生更大的权重误差。
    *   **结果**: `find_nn` 会为每个 `bin` 计算出它的最近邻 `nn` 和合并误差 `err`。

2.  **使用最小堆进行高效合并**: 如果每次都遍历所有 `bin` 来寻找全局最小误差对，效率会很低。`PnnQuant` 使用了**最小堆**这种数据结构来解决这个问题。
    *   **堆的初始化**: 所有 `bin` 根据它们的合并误差 `err` 被放入一个最小堆中。堆顶的元素永远是那个合并误差最小的 `bin`。
    *   **迭代合并**: 算法执行 `maxbins - nMaxColors` 次合并操作。在每次循环中：
        a.  **提取最小**: 从堆顶取出一个 `bin`（我们称之为 `b1`）。这个 `b1` 和它的最近邻 `b2` (即 `b1.nn`) 就是当前整个图像中“最适合合并”的一对。
        b.  **执行合并**: 将 `b2` 的颜色和像素数加权平均到 `b1` 中。
        c.  **更新数据结构**: 将 `b2` 标记为“已删除”，并从 `bin` 的双向链表中移除。
        d.  **重新计算**: 因为 `b2` 被移除了，一些之前以 `b2` 为最近邻的 `bin`，以及 `b1` 自身，都需要重新调用 `find_nn` 来寻找新的最近邻和新的合并误差。
        e.  **更新堆**: 将这些受影响的 `bin` 以其新的误差值更新在堆中的位置。

这个过程不断重复，每次都合并全局最优的一对，直到 `bin` 的数量达到 `nMaxColors`。

### 2.3. 颜色映射与抖动 (`quantize_image` 方法)

调色板生成后，最后一步就是将原始图像像素映射到调色板上。

*   **抖动 (`dither = true`)**: `PnnQuant` 实现了一种高质量的、类似 Floyd-Steinberg 的**错误扩散抖动算法**。
    *   它逐行扫描图像（支持蛇形扫描 `serpentine`）。
    *   对于每个像素，它会加上从前面像素扩散过来的累计误差，然后再去调色板中寻找最近的颜色。
    *   计算出新的量化误差（当前色与调色板色的差值），并将其按特定比例扩散给未来的、尚未处理的邻近像素。
    *   这种方法可以极好地模拟颜色渐变，效果远优于简单的最近色替换。

*   **无抖动 (`dither = false`)**:
    *   它会调用 `closestColorIndex` 函数。这个函数更有趣，它不仅仅是寻找最近的颜色。
    *   它会为每个像素找出调色板中**最接近的两个颜色** (`closest[0]` 和 `closest[1]`)。
    *   然后，根据像素的位置（奇偶）和一些预计算的**蓝噪声 (`TELL_BLUE_NOISE`)** 值，在这两个最接近的颜色中选择一个。这是一种**有序抖动 (Ordered Dithering)**，性能比错误扩散快，效果也比单纯的最近色替换好。

### 2.4. 总结与图示

`PnnQuant` 是一个非常精巧和高效的算法。它通过**颜色位深度压缩**和**基于堆的最近邻合并**两大核心技术，在速度和质量上都取得了很好的平衡。

*   **相比 `RgbQuant`**:
    *   **性能**: `PnnQuant` 通常远快于 `RgbQuant`。`RgbQuant` 的聚类是 `O(N^2)` 复杂度的，而 `PnnQuant` 基于堆的实现接近 `O(N log N)`。
    *   **质量**: `PnnQuant` 的合并策略（总是合并误差最小的）通常能产生更符合人类视觉感知的调色板。

```mermaid
graph TD
    subgraph "1. 预量化与直方图 (Binning)"
        A[原始图像] --> B[遍历所有像素];
        B --> C{"getARGBIndex(pixel)"};
        C --> D[将 24/32bit 颜色映射到 16bit 索引];
        D --> E[在 bins[] 数组中累加颜色和数量];
        E --> F[计算每个 bin 的平均色];
    end

    subgraph "2. 层次聚类 (Clustering)"
        F --> G[为每个 bin 计算最近邻(nn)和合并误差(err)];
        G --> H[将所有 bin 根据 err 构建一个最小堆];
        H --> I{循环 N 次 (直到数量达标)};
        I -- "是" --> J[从堆顶取出误差最小的 bin];
        J --> K[合并该 bin 和它的最近邻];
        K --> L[更新受影响的 bin 的 nn 和 err];
        L --> M[调整堆];
        M --> I;
        I -- "否" --> N[最终调色板];
    end

    subgraph "3. 颜色映射 (Mapping)"
        O[原始图像] --> P{选择映射方式};
        N --> P;
        P -- "有序抖动" --> Q1[为像素找最接近的2个颜色, 用蓝噪声选择其一];
        P -- "错误扩散抖动" --> Q2[找最近色, 并将误差扩散到邻近像素];
        Q1 --> R[最终量化图像];
        Q2 --> R;
    end
```

---

## 3. GpuQuant.js 逻辑分析

这套方案是我们为追求极致性能而设计的**“专业分工”**架构。它将原 `PnnQuant` 算法拆分为两部分，分别交由最适合的处理器执行。

*   **CPU**: 负责处理复杂的、串行的、难以在 GPU 上高效实现的**调色板生成**任务。
*   **GPU**: 负责处理简单的、但计算量巨大、高度并行的**颜色映射**任务，利用 Three.js 的着色器接口。

### 3.1. CPU: 专注的调色板生成器

这个文件是对原版 `pnnquant.js` 进行**“外科手术式”改造**的结果，只保留了其最高效、最核心的功能：

*   **保留的核心**:
    1.  **颜色空间降维与直方图构建**: 依然使用高效的 `getARGBIndex` 来预量化颜色。
    2.  **基于最小误差的迭代合并**: 依然使用 `find_nn` 和最小堆来执行核心的层次聚类算法。

*   **移除的部分**:
    1.  **颜色映射与抖动**: 所有与最终图像渲染相关的函数（如 `nearestColorIndex`, `closestColorIndex`, `quantize_image`）都被完全移除。

*   **新的 API**:
    *   这个模块现在只对外暴露一个核心方法：**`generatePalette()`**。
    *   它的职责非常单一：接收原始像素数据和目标颜色数，执行 `pnnquan` 算法，然后返回一个 `Uint32Array` 格式的调色板。

### 3.2. GPU: 大规模并行颜色映射器

这个模块接管了颜色映射工作，并将其放在 GPU 上执行以获得数量级的性能提升。其核心方法是 **`quantize(imageTexture, palette)`**，工作流程如下：

1.  **准备输入数据**:
    *   **调色板纹理**: 将一维的 `palette` 数组转换成一个二维的 `THREE.DataTexture`，供 GPU 读取。
    *   **原始图像纹理**: 直接接收一个 `THREE.Texture` 对象。

2.  **设置着色器 (Shader)**:
    *   将**原始图像纹理**和**调色板纹理**作为 `uniform sampler2D` 变量传递给 GLSL 着色器。

3.  **离屏渲染**:
    *   创建一个与原始图像等大的**离屏渲染目标** (`THREE.WebGLRenderTarget`)。
    *   使用 `Pass.FullScreenQuad` 高效地渲染一个全屏矩形，目的是为图像中的每一个像素都执行一次**片段着色器 (Fragment Shader)**。

4.  **执行核心计算 (在片段着色器中)**:
    *   **Y 轴翻转**: 翻转 UV 坐标以正确采样原始图像。
    *   **遍历调色板**: 对于每一个像素，片段着色器会循环遍历调色板中的所有颜色。
    *   **查找最近色**: 计算当前像素与每个调色板颜色的**平方欧氏距离**，并记录距离最小的那个颜色。
    *   **输出结果**: 循环结束后，将找到的最佳匹配色作为当前像素的最终颜色（`gl_FragColor`）输出到离屏渲染目标。

5.  **回读数据与清理**:
    *   渲染完成后，使用 `renderer.readRenderTargetPixels()` 将 GPU 显存中的量化结果图像读回到 CPU 的一个 `Uint8ClampedArray` 数组中。
    *   调用 `dispose()` 方法释放 GPU 资源。

### 3.3. 总结与图示

这套 CPU+GPU 混合方案是现代 Web 图形处理的典范。它精确地划分了任务边界，让两类处理器各司其职，性能瓶颈通常只剩下数据在 CPU 与 GPU 之间的传输。

```mermaid
graph TD
    subgraph "CPU Domain"
        A[原始图像像素] --> B(generatePalette);
        B --> C[执行PNN层次聚类算法];
        C --> D[生成调色板 (Uint32Array)];
    end

    subgraph "GPU Domain"
        E[原始图像纹理] --> F(quantize);
        D --> F;
        F --> G[创建调色板纹理];
        G --> H[设置离屏渲染目标];
        H --> I[执行全屏片元着色器];
        subgraph "Fragment Shader (for each pixel)"
            J[读取原始像素色] --> K[循环遍历调色板];
            K --> L[计算与调色板颜色的距离];
            L --> M[找到距离最小的颜色];
            M --> N[输出该颜色];
        end
        I --> O[渲染结果到纹理];
        O --> P[从GPU回读像素数据];
        P --> Q[最终量化图像 (Uint8ClampedArray)];
    end
```